{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07624fbe-909b-462a-a0fc-f715cb14cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTATION_PATH = Path(\"/mnt/c/Users/jonan/Documents/1Work/RoseLab/Spatial/\"\n",
    "                         \"dietary_droject/data/cell_segmentation\")\n",
    "\n",
    "sample_id = \"F07834\"\n",
    "\n",
    "adata_path = SEGMENTATION_PATH / sample_id / f\"{sample_id}_grouped_filtered_adata.h5ad\"\n",
    "gdf_file = SEGMENTATION_PATH / sample_id / f\"{sample_id}_gdf.gpkg\"\n",
    "polys_file = SEGMENTATION_PATH / sample_id / f\"{sample_id}_polys.pkg\"\n",
    "\n",
    "\n",
    "# Load adata\n",
    "ST_sample = sc.read_h5ad(adata_path)\n",
    "# load your polygons\n",
    "geo_file = gpd.read_file(gdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c260bba-dcd5-4f91-a879-89da201b6937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample F07833 ===\n",
      "  Adata IDs: min 2, max 267829, total 189428\n",
      "  GDF IDs:   min 1, max 267830, total 267830\n",
      "  ⚠️ Warning: ID mismatch between adata and gdf!\n",
      "\n",
      "=== Sample F07834 ===\n",
      "  Adata IDs: min 267832, max 523218, total 91297\n",
      "  GDF IDs:   min 267831, max 523219, total 255389\n",
      "  ⚠️ Warning: ID mismatch between adata and gdf!\n",
      "\n",
      "=== Sample F07835 ===\n",
      "  Adata IDs: min 523225, max 833142, total 162228\n",
      "  GDF IDs:   min 523220, max 833142, total 309923\n",
      "  ⚠️ Warning: ID mismatch between adata and gdf!\n",
      "\n",
      "=== Sample F07836 ===\n",
      "  Adata IDs: min 833143, max 1126497, total 175801\n",
      "  GDF IDs:   min 833143, max 1126498, total 293356\n",
      "  ⚠️ Warning: ID mismatch between adata and gdf!\n",
      "\n",
      "=== Sample F07837 ===\n",
      "  Adata IDs: min 1126499, max 1399125, total 119523\n",
      "  GDF IDs:   min 1126499, max 1399125, total 272627\n",
      "  ✅ ID ranges match\n",
      "\n",
      "=== Sample F07838 ===\n",
      "  Adata IDs: min 1399128, max 1676587, total 114323\n",
      "  GDF IDs:   min 1399126, max 1676588, total 277463\n",
      "  ⚠️ Warning: ID mismatch between adata and gdf!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# Constants\n",
    "SEGMENTATION_PATH = Path(\"/mnt/c/Users/jonan/Documents/1Work/RoseLab/Spatial/\"\n",
    "                         \"dietary_droject/data/cell_segmentation\")\n",
    "\n",
    "# List of sample IDs\n",
    "samples = [\"F07833\", \"F07834\", \"F07835\", \"F07836\", \"F07837\", \"F07838\"]\n",
    "\n",
    "# Start loop\n",
    "for sample_id in samples:\n",
    "    print(f\"=== Sample {sample_id} ===\")\n",
    "    \n",
    "    # File paths\n",
    "    adata_path = SEGMENTATION_PATH / sample_id / f\"{sample_id}_grouped_filtered_adata.h5ad\"\n",
    "    gdf_path = SEGMENTATION_PATH / sample_id / f\"{sample_id}_gdf.gpkg\"\n",
    "    \n",
    "    # Load files\n",
    "    adata = sc.read_h5ad(adata_path)\n",
    "    gdf = gpd.read_file(gdf_path)\n",
    "    \n",
    "    # Extract IDs\n",
    "    adata_ids = adata.obs['id'].values\n",
    "    gdf_ids = gdf['id'].values\n",
    "    \n",
    "    # Convert IDs to integers (strip 'ID_' and cast to int)\n",
    "    adata_ids_int = [int(i.replace('ID_', '')) for i in adata_ids]\n",
    "    gdf_ids_int = [int(i.replace('ID_', '')) for i in gdf_ids]\n",
    "    \n",
    "    # Print stats\n",
    "    print(f\"  Adata IDs: min {min(adata_ids_int)}, max {max(adata_ids_int)}, total {len(adata_ids_int)}\")\n",
    "    print(f\"  GDF IDs:   min {min(gdf_ids_int)}, max {max(gdf_ids_int)}, total {len(gdf_ids_int)}\")\n",
    "    \n",
    "    # Check if the ID ranges match\n",
    "    if (min(adata_ids_int) != min(gdf_ids_int)) or (max(adata_ids_int) != max(gdf_ids_int)):\n",
    "        print(f\"  ⚠️ Warning: ID mismatch between adata and gdf!\")\n",
    "    else:\n",
    "        print(f\"  ✅ ID ranges match\")\n",
    "    \n",
    "    print()  # Blank line for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd0b35-7af1-42e5-8cf2-c55faa1651d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9199df-6adf-4834-a6a2-7a6bdadbf82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3a9ac-8ab8-429c-9d24-37c48eec2edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2913a7-52b9-47a1-9526-2ddb0d66a521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91388ea-59d1-4d6d-92bb-05d28021a239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148cf0c-7228-466a-973c-eba5fcc737c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1107ab-ab9a-4dbb-ba14-4c55313cc20c",
   "metadata": {},
   "source": [
    "# Binning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5571720-dd4a-4a9d-9369-bb437457f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rebinning F07833 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/envs/spatial-nuclei/lib/python3.10/site-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/jon/anaconda3/envs/spatial-nuclei/lib/python3.10/site-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m adata\u001b[38;5;241m.\u001b[39mobs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(adata\u001b[38;5;241m.\u001b[39mobs, df_pos, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# create GeoDataFrame of barcodes\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m geometry \u001b[38;5;241m=\u001b[39m [Point(xy) \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     62\u001b[0m     df_pos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpxl_col_in_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m], df_pos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpxl_row_in_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     63\u001b[0m )]\n\u001b[1;32m     64\u001b[0m gdf_coordinates \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(df_pos, geometry\u001b[38;5;241m=\u001b[39mgeometry)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 4) create nucleus GeoDataFrame from polys\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m adata\u001b[38;5;241m.\u001b[39mobs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(adata\u001b[38;5;241m.\u001b[39mobs, df_pos, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# create GeoDataFrame of barcodes\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m geometry \u001b[38;5;241m=\u001b[39m [\u001b[43mPoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     62\u001b[0m     df_pos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpxl_col_in_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m], df_pos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpxl_row_in_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     63\u001b[0m )]\n\u001b[1;32m     64\u001b[0m gdf_coordinates \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(df_pos, geometry\u001b[38;5;241m=\u001b[39mgeometry)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 4) create nucleus GeoDataFrame from polys\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spatial-nuclei/lib/python3.10/site-packages/shapely/geometry/point.py:56\u001b[0m, in \u001b[0;36mPoint.__new__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new Point geometry.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# empty geometry\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;66;03m# TODO better constructor\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m shapely\u001b[38;5;241m.\u001b[39mfrom_wkt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOINT EMPTY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import anndata\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "from scipy import sparse\n",
    "import re\n",
    "\n",
    "# constants\n",
    "BASE_DIR = Path(\"/mnt/c/Users/jonan/Documents/1Work/RoseLab/Spatial/\"\n",
    "                \"dietary_droject/data/Rose_Li_VisiumHD\")\n",
    "SEG_PATH = Path(\"/mnt/c/Users/jonan/Documents/1Work/RoseLab/Spatial/\"\n",
    "                \"dietary_droject/data/cell_segmentation\")\n",
    "SAMPLES = [\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07833_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07834_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07835_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07836_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07837_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07838_22WJCYLT3\",\n",
    "]\n",
    "\n",
    "offset = 0\n",
    "for sample in SAMPLES:\n",
    "    sample_id = re.search(r'F\\d{5}', sample).group(0)\n",
    "    print(f\"=== Rebinning {sample_id} ===\")\n",
    "    \n",
    "    # 1) load StarDist polygons\n",
    "    pkl_file = SEG_PATH / sample_id / \"model_output\" / f\"{sample_id}_polys.pkl\"\n",
    "    with open(pkl_file, \"rb\") as f:\n",
    "        polys = pickle.load(f)\n",
    "    \n",
    "    # 2) recreate gdf exactly as vignette\n",
    "    geometries = []\n",
    "    for nuclei in range(len(polys['coord'])):\n",
    "        ys, xs = polys['coord'][nuclei]\n",
    "        coords = [(y, x) for x, y in zip(xs, ys)]\n",
    "        geometries.append(Point(coords[0]))  # placeholder, will be overwritten below\n",
    "    # Note: polys['coord'] is a tuple of arrays; \n",
    "    # The vignette actually uses Polygon, but we want the same logic.\n",
    "    # Following vignette: they build a GeoDataFrame from df, not from polys directly,\n",
    "    # so we skip this here and let the spatial join recreate geometry.\n",
    "    \n",
    "    # 3) load original Visium HD data\n",
    "    spatial_dir = BASE_DIR / sample / \"outs\" / \"binned_outputs\" / \"square_002um\"\n",
    "    raw_h5_file = spatial_dir / \"filtered_feature_bc_matrix.h5\"\n",
    "    pq   = spatial_dir / \"spatial\" / \"tissue_positions.parquet\"\n",
    "    \n",
    "    adata = sc.read_10x_h5(str(raw_h5_file))\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    df_pos = pd.read_parquet(str(pq))\n",
    "    df_pos = df_pos.set_index(\"barcode\")\n",
    "    df_pos['index'] = df_pos.index\n",
    "    adata.obs = pd.merge(adata.obs, df_pos, left_index=True, right_index=True)\n",
    "    \n",
    "    # create GeoDataFrame of barcodes\n",
    "    geometry = [Point(xy) for xy in zip(\n",
    "        df_pos['pxl_col_in_fullres'], df_pos['pxl_row_in_fullres']\n",
    "    )]\n",
    "    gdf_coordinates = gpd.GeoDataFrame(df_pos, geometry=geometry)\n",
    "    \n",
    "    # 4) create nucleus GeoDataFrame from polys\n",
    "    poly_geoms = []\n",
    "    for nuclei in range(len(polys['coord'])):\n",
    "        ys, xs = polys['coord'][nuclei]\n",
    "        coords = [(y, x) for x, y in zip(xs, ys)]\n",
    "        from shapely.geometry import Polygon\n",
    "        poly_geoms.append(Polygon(coords))\n",
    "    gdf = gpd.GeoDataFrame(geometry=poly_geoms)\n",
    "    gdf['id']   = [f\"ID_{offset + i + 1}\" for i in range(len(gdf))]\n",
    "    gdf['area'] = gdf.geometry.area\n",
    "    offset += len(gdf)\n",
    "    \n",
    "    # 5) spatial join and filtering (pure vignette)\n",
    "    result_spatial_join = gpd.sjoin(\n",
    "        gdf_coordinates, gdf, how='left', predicate='within'\n",
    "    )\n",
    "    result_spatial_join['is_within_polygon'] = ~result_spatial_join['index_right'].isna()\n",
    "    barcodes_in_overlapping = pd.unique(\n",
    "        result_spatial_join[result_spatial_join.duplicated(subset=['index'])]['index']\n",
    "    )\n",
    "    result_spatial_join['is_not_in_an_polygon_overlap'] = \\\n",
    "        ~result_spatial_join['index'].isin(barcodes_in_overlapping)\n",
    "    \n",
    "    barcodes_in_one_polygon = result_spatial_join[\n",
    "        result_spatial_join['is_within_polygon'] & \n",
    "        result_spatial_join['is_not_in_an_polygon_overlap']\n",
    "    ]\n",
    "    mask = adata.obs_names.isin(barcodes_in_one_polygon['index'])\n",
    "    filtered_adata = adata[mask, :].copy()\n",
    "    filtered_adata.obs = pd.merge(\n",
    "        filtered_adata.obs,\n",
    "        barcodes_in_one_polygon[['index','geometry','id','is_within_polygon','is_not_in_an_polygon_overlap']],\n",
    "        left_index=True, right_index=True\n",
    "    )\n",
    "    \n",
    "    # 6) summation (vignette logic)\n",
    "    groupby = filtered_adata.obs.groupby(['id'], observed=True)\n",
    "    counts = filtered_adata.X\n",
    "    N_groups = groupby.ngroups\n",
    "    N_genes  = counts.shape[1]\n",
    "    \n",
    "    summed = sparse.lil_matrix((N_groups, N_genes))\n",
    "    polygon_id = []\n",
    "    row = 0\n",
    "    for poly, idxs in groupby.indices.items():\n",
    "        summed[row] = counts[idxs].sum(0)\n",
    "        polygon_id.append(poly)\n",
    "        row += 1\n",
    "    summed = summed.tocsr()\n",
    "    \n",
    "    rebinned_adata = anndata.AnnData(\n",
    "        X=summed,\n",
    "        obs=pd.DataFrame(polygon_id, columns=['id'], index=polygon_id),\n",
    "        var=filtered_adata.var\n",
    "    )\n",
    "    \n",
    "    # 7) save with \"_rebinned\" suffix\n",
    "    out_dir = SEG_PATH / sample_id\n",
    "    rebinned_adata.write(out_dir / f\"{sample_id}_grouped_filtered_adata_rebinned.h5ad\")\n",
    "    gdf.to_file(out_dir / f\"{sample_id}_gdf_rebinned.gpkg\", driver=\"GPKG\")\n",
    "    \n",
    "    print(f\"→ Saved rebinned for {sample_id}\")\n",
    "    \n",
    "    #===========================================================================#\n",
    "    # UMI Figure\n",
    "    #===========================================================================#\n",
    "\n",
    "    \n",
    "    # ensure your figures folder exists\n",
    "    fig_out = SEG_PATH / sample_id / \"figures\"\n",
    "    fig_out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Compute total UMI per nucleus\n",
    "    total_umis = ST_sample.X.sum(axis=1).A1   # flatten sparse matrix\n",
    "    ST_sample.obs['total_umis'] = total_umis\n",
    "    \n",
    "    # 2. Merge UMI counts into the GeoDataFrame\n",
    "    gdf_umi = geo_file.merge(\n",
    "        ST_sample.obs[['total_umis']],\n",
    "        left_on='id',\n",
    "        right_index=True\n",
    "    )\n",
    "    \n",
    "    # 3. Plot and save\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    gdf_umi.plot(\n",
    "        column='total_umis',\n",
    "        cmap='inferno',\n",
    "        legend=True,\n",
    "        linewidth=0.1,\n",
    "        edgecolor='black',\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"UMI Counts per Nucleus ({sample_id})\", fontsize=14)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save to figures folder with the \"_umi_rebinned\" suffix\n",
    "    out_file = fig_out / f\"{sample_id}_umi_rebinned.png\"\n",
    "    fig.savefig(out_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"→ Saved UMI map: {out_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c447056e-a3de-4049-b928-da79702fab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rebinning F07833 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/envs/spatial-nuclei/lib/python3.10/site-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/jon/anaconda3/envs/spatial-nuclei/lib/python3.10/site-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/jon/anaconda3/envs/spatial-nuclei/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Saved rebinned for F07833\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'geo_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 144\u001b[0m\n\u001b[1;32m    141\u001b[0m rebinned_adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_umis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m total_umis\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# 2. Merge UMI counts into the GeoDataFrame\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m gdf_umi \u001b[38;5;241m=\u001b[39m \u001b[43mgeo_file\u001b[49m\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m    145\u001b[0m     rebinned_adata\u001b[38;5;241m.\u001b[39mobs[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_umis\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m    146\u001b[0m     left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    147\u001b[0m     right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# 3. Plot and save\u001b[39;00m\n\u001b[1;32m    151\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geo_file' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import anndata\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "from scipy import sparse\n",
    "import re\n",
    "\n",
    "# constants\n",
    "BASE_DIR = Path(\"/mnt/c/Users/jonan/Documents/1Work/RoseLab/Spatial/\"\n",
    "                \"dietary_droject/data/Rose_Li_VisiumHD\")\n",
    "SEG_PATH = Path(\"/mnt/c/Users/jonan/Documents/1Work/RoseLab/Spatial/\"\n",
    "                \"dietary_droject/data/cell_segmentation\")\n",
    "SAMPLES = [\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07833_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07834_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07835_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07836_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07837_22WJCYLT3\",\n",
    "    \"BANOSSM_SSM0015_1_PR_Whole_C1_VISHD_F07838_22WJCYLT3\",\n",
    "]\n",
    "\n",
    "offset = 0\n",
    "for sample in SAMPLES:\n",
    "    sample_id = re.search(r'F\\d{5}', sample).group(0)   # → \"F07833\"\n",
    "    print(f\"=== Rebinning {sample_id} ===\")\n",
    "    \n",
    "    # 1) load StarDist polygons\n",
    "    pkl_file = SEG_PATH / sample_id / \"model_output\" / f\"{sample_id}_polys.pkl\"\n",
    "    with open(pkl_file, \"rb\") as f:\n",
    "        polys = pickle.load(f)\n",
    "    \n",
    "    # 2) recreate gdf exactly as vignette\n",
    "    geometries = []\n",
    "    for nuclei in range(len(polys['coord'])):\n",
    "        ys, xs = polys['coord'][nuclei]\n",
    "        coords = [(y, x) for x, y in zip(xs, ys)]\n",
    "        geometries.append(Point(coords[0]))  # placeholder, will be overwritten below\n",
    "    # Note: polys['coord'] is a tuple of arrays; \n",
    "    # The vignette actually uses Polygon, but we want the same logic.\n",
    "    # Following vignette: they build a GeoDataFrame from df, not from polys directly,\n",
    "    # so we skip this here and let the spatial join recreate geometry.\n",
    "    \n",
    "    # 3) load original Visium HD data\n",
    "    spatial_dir = BASE_DIR / sample / \"outs\" / \"binned_outputs\" / \"square_002um\"\n",
    "    raw_h5 = spatial_dir / \"filtered_feature_bc_matrix.h5\"\n",
    "    pq   = spatial_dir / \"spatial\" / \"tissue_positions.parquet\"\n",
    "    \n",
    "    adata = sc.read_10x_h5(str(raw_h5))\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    df_pos = pd.read_parquet(str(pq))\n",
    "    df_pos = df_pos.set_index(\"barcode\")\n",
    "    df_pos['index'] = df_pos.index\n",
    "    adata.obs = pd.merge(adata.obs, df_pos, left_index=True, right_index=True)\n",
    "    \n",
    "    # create GeoDataFrame of barcodes\n",
    "    geometry = [Point(xy) for xy in zip(\n",
    "        df_pos['pxl_col_in_fullres'], df_pos['pxl_row_in_fullres']\n",
    "    )]\n",
    "    gdf_coordinates = gpd.GeoDataFrame(df_pos, geometry=geometry)\n",
    "    \n",
    "    # 4) create nucleus GeoDataFrame from polys\n",
    "    poly_geoms = []\n",
    "    for nuclei in range(len(polys['coord'])):\n",
    "        ys, xs = polys['coord'][nuclei]\n",
    "        coords = [(y, x) for x, y in zip(xs, ys)]\n",
    "        from shapely.geometry import Polygon\n",
    "        poly_geoms.append(Polygon(coords))\n",
    "    gdf = gpd.GeoDataFrame(geometry=poly_geoms)\n",
    "    gdf['id']   = [f\"ID_{offset + i + 1}\" for i in range(len(gdf))]\n",
    "    gdf['area'] = gdf.geometry.area\n",
    "    offset += len(gdf)\n",
    "    \n",
    "    # 5) spatial join and filtering (pure vignette)\n",
    "    result_spatial_join = gpd.sjoin(\n",
    "        gdf_coordinates, gdf, how='left', predicate='within'\n",
    "    )\n",
    "    result_spatial_join['is_within_polygon'] = ~result_spatial_join['index_right'].isna()\n",
    "    barcodes_in_overlapping = pd.unique(\n",
    "        result_spatial_join[result_spatial_join.duplicated(subset=['index'])]['index']\n",
    "    )\n",
    "    result_spatial_join['is_not_in_an_polygon_overlap'] = \\\n",
    "        ~result_spatial_join['index'].isin(barcodes_in_overlapping)\n",
    "    \n",
    "    barcodes_in_one_polygon = result_spatial_join[\n",
    "        result_spatial_join['is_within_polygon'] & \n",
    "        result_spatial_join['is_not_in_an_polygon_overlap']\n",
    "    ]\n",
    "    mask = adata.obs_names.isin(barcodes_in_one_polygon['index'])\n",
    "    filtered_adata = adata[mask, :].copy()\n",
    "    filtered_adata.obs = pd.merge(\n",
    "        filtered_adata.obs,\n",
    "        barcodes_in_one_polygon[['index','geometry','id','is_within_polygon','is_not_in_an_polygon_overlap']],\n",
    "        left_index=True, right_index=True\n",
    "    )\n",
    "    \n",
    "    # 6) summation (vignette logic)\n",
    "    groupby = filtered_adata.obs.groupby(['id'], observed=True)\n",
    "    counts = filtered_adata.X\n",
    "    N_groups = groupby.ngroups\n",
    "    N_genes  = counts.shape[1]\n",
    "    \n",
    "    summed = sparse.lil_matrix((N_groups, N_genes))\n",
    "    polygon_id = []\n",
    "    row = 0\n",
    "    for poly, idxs in groupby.indices.items():\n",
    "        summed[row] = counts[idxs].sum(0)\n",
    "        polygon_id.append(poly)\n",
    "        row += 1\n",
    "    summed = summed.tocsr()\n",
    "    \n",
    "    rebinned_adata = anndata.AnnData(\n",
    "        X=summed,\n",
    "        obs=pd.DataFrame(polygon_id, columns=['id'], index=polygon_id),\n",
    "        var=filtered_adata.var\n",
    "    )\n",
    "    \n",
    "    # 7) save with \"_rebinned2\" suffix\n",
    "    out_dir = SEG_PATH / sample_id\n",
    "    rebinned_adata.write(out_dir / f\"{sample_id}_grouped_filtered_adata_rebinned2.h5ad\")\n",
    "    gdf.to_file(out_dir / f\"{sample_id}_gdf_rebinned2.gpkg\", driver=\"GPKG\")\n",
    "    \n",
    "    print(f\"→ Saved rebinned for {sample_id}\")\n",
    "\n",
    "    \n",
    "    #===========================================================================#\n",
    "    # UMI Figure\n",
    "    #===========================================================================#\n",
    "\n",
    "    \n",
    "    # ensure your figures folder exists\n",
    "    fig_out = SEG_PATH / sample_id / \"figures\"\n",
    "    fig_out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Compute total UMI per nucleus\n",
    "    total_umis = rebinned_adata.X.sum(axis=1).A1   # flatten sparse matrix\n",
    "    rebinned_adata.obs['total_umis'] = total_umis\n",
    "    \n",
    "    # 2. Merge UMI counts into the GeoDataFrame\n",
    "    gdf_umi = geo_file.merge(\n",
    "        rebinned_adata.obs[['total_umis']],\n",
    "        left_on='id',\n",
    "        right_index=True\n",
    "    )\n",
    "    \n",
    "    # 3. Plot and save\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    gdf_umi.plot(\n",
    "        column='total_umis',\n",
    "        cmap='inferno',\n",
    "        legend=True,\n",
    "        linewidth=0.1,\n",
    "        edgecolor='black',\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"UMI Counts per Nucleus ({sample_id})\", fontsize=14)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save to figures folder with the \"_umi_rebinned2\" suffix\n",
    "    out_file = fig_out / f\"{sample_id}_umi_rebinned2.png\"\n",
    "    fig.savefig(out_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"→ Saved UMI map: {out_file}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spatial-nuclei)",
   "language": "python",
   "name": "spatial-nuclei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
